{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Representation Learning\"\n",
    "> \"An overview of representation learning\"\n",
    "\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: false\n",
    "- comments: true\n",
    "- categories: [fastpages, jupyter]\n",
    "- image: images/repl_title.jpg\n",
    "- hide: false\n",
    "- search_exclude: true\n",
    "- metadata_key1: metadata_value1\n",
    "- metadata_key2: metadata_value2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## About\n",
    "\n",
    "Representation learning is the process of learning/extracting meaningful representations to make the computations of subsequent ML tasks easier. \n",
    "\n",
    "### Why we need good representations?\n",
    "\n",
    "Success of any machine learning method depends on the representation of data. Better the representation, easier for the machine learning algorithm to interpret the data, to produce accurate results. \n",
    "\n",
    "Assume you are asked to write a program, that should return \"True\" if the input no is divisible by 2, otherwise \"False\". Just think how you would write it.\n",
    "\n",
    "Now if i pass the input no as a \"Roman numeral\" (say XXVIII representing 28) would your program still output correct result?\n",
    "\n",
    "Most of our programs struggle to interpret the representation and so may fail to give desired results. However if the input is represented as decimal integer, the output would be correct\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](my_icons/image1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same way, ML algorithms would also NOT produce accurate results if the data represenation is not good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what if the representation is not learnt?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think about classic ML algorithms like Decision trees, Random forests, Naive bayes etc. They dont learn representations from input data. All they do is map input features to output in their own way.\n",
    "Without learning representations, these algorithms rely on Feature Engineering \n",
    "\n",
    "Feature Engineering ensures selection of data features that are important to achieve the particular ML task.\n",
    "With feature engineering, the human knowledge about the task, especially the factors influencing/causing the tasks are passed on to the ML algorithm\n",
    "    \n",
    "> For eg. Lets take the example of IRIS flower classification task.Algorithms would struggle to classify if the features are irrelevant. It is beacuse the features were carefully chosen with the help of the domain experts (thanks to feature engineering) the algorithms could predict decently. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](my_icons/image6.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering has certain limitations:\n",
    "- FE cannot be carried for a task where minimal domain knowledge exists\n",
    "- Difficult to extract features from high dimensional, raw data eg. machine logs\n",
    "- Very time consuming process\n",
    "- Depends on domain knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    >   ...feature  engineering  is  important  butlabor-intensive and highlights the weakness of current learningalgorithms: their inability to extract and organize the discrimi-native information from the data. Feature engineering is a wayto take advantage of human ingenuity and prior knowledge tocompensate  for  that  weakness\n",
    "    - \"Representation Learning: A Review and NewPerspectives\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering only guarantee the important features are taken for the task. But that alone doesnot help. It is equally important to have the features represented in a meaningful way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at few scenarios where classic ML methods that donot learn representations suffer -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **Generalization**\n",
    "\n",
    "    Algorithms that donot learn representations, do not generalize beyond the scope of problem / task.\n",
    "\n",
    "    For eg: Say we have trained a Random Forest algorithm to classify Iris flowers. The algorithm would be able to     classify correctly even for the data points it has not seen. That means, it is able to perform (local) generalization within the scope of task.\n",
    "\n",
    "    But the mapping or knowledge it has learnt, cannot be used for classifying other types of flowers eventhough same features are taken into consideration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **Vast Sample Space & Complex relationships**\n",
    "\n",
    "   Think of an image Classification problem, where each pixel (across RGB channels) is a feature taking value between 0 and 255. Sample space of Image domain is so vast that it is nearly impossible to capture the complex non linear relationships exists between input and output without learning intermediate/abstract representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **Conditional dependence**\n",
    "\n",
    "   If there exist a conditional dependence between input features, the algorithms would suffer to interpret and produce correct results, without learning representations.\n",
    "   \n",
    "   For eg: Images, text, audio etc\n",
    "   \n",
    "   Objects in images are created by combination of pixels and hence the pixel values are highly corelated.Classic ML methods would not be able to model this conditional dependence.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above said problems can be solved by learning representations from data, and then derive output from the representations. This is how deep learning do!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a model that can infer meaningful structure from input data. This is where deep learning excels.\n",
    "So the term 'Representation learning' is often used in synonymous with Deep learning.\n",
    "\n",
    "> Core idea behind representation learning is\n",
    "- map high dimensional sample space to low dimensional latent space . The latent space is a \"Representation\"\n",
    "- Learn a mapping from low dimensional latent space to actual output domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this representation learning, we dont have to directly map the high dimensional sample space to features. Rather we learn abstract representations and use that to derive outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning does the same. It learns abstract representations in series of layers. Representation in each layer is learnt from previous layer's representation. As the network goes deeper (more layers), the abstraction increases and from the representation of final layer(s), the output is inferred.Success of Deep learning is mainly due to its ability to learn representations from data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are the problems of ML Solved?\n",
    "\n",
    "Though Deep Learning has solved many complex problems, there exists some key issue to be addressed :\n",
    "Data Hungry : Deep \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to evaluate a representation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few important factors that make a good representation are\n",
    "\n",
    "+ **Prior**\n",
    "\n",
    "  A representation should carry information about the real world factors. In other words, the representation should reveal the underlying factors used to construct the data point.\n",
    "  For eg: Lets ask a graphics software to draw a fruit specifying its size, color and what fruit it is. we specify it as \"small, red, apple\". The software creates a nice image. It is then fed into a ML algorithm to learn represenations from the image. There are many ways that an algorithm could learn representations. As long as the representations reveal few or more underlying factors that formed the image (in this case - size,color and fruit), it would be helpful to achieve a vaierty of tasks\n",
    "![](my_icons/image8.jpg)  \n",
    "  \n",
    "+ **Abstraction**\n",
    "    Human beings can learn a new concept with just couple of examples. Even a 3yr old kid could easily distinguish a car from bicycle, after seeing couple of instances. whereas ML models require hundreds or thousands of examples to understand a concept. One reason why human beings learn any concept quickly because, human mind learns rich abstract concepts(representations) from visual perception. In rough sense, a car is interpreted as a collection of abstract concepts such as wheels,engine,seats etc. These abstract representations help humans towards - action, imagination, and explanation\n",
    "    \n",
    "    In a similar way, ML models also should learn abstract representations from the data points. These abstract representations would help to build a more robust AI solution as these abstract concepts can be combined hierarchially to represent high abstract concepts(2-wheeler/4-wheeler). \n",
    "    \n",
    "    Just like humans, these represenations are helpful for subsequent ML models to take action(eg.classification), form imagination(Generative modeling) and create explanation(Interpretability)\n",
    "![](my_icons/image9.jpg)    \n",
    "    \n",
    "+ **Disentanglement**\n",
    "    As mentioned in the Prior section, every real world datapoint is created one or more factors,called *Generative factors*. These factors may either be independent or dependent. Factors that are not sensitive to changes in other factors are independent factors. For eg: consider \"Small, red, apple\" .These factors (size,color and fruit) are all independent. Change in one factor doesnot influence other. Whereas lets consider diagonal in a rectangle, the diagonal coordinates are sensitive to change in height or width of rectangle. These are all dependent factors.\n",
    "![](my_icons/image10.png)\n",
    "    In representation learning(usually in DL)  high dimensional data points(say, images) are modeled in low dimensional latent space, which we call it as *Representations* or *Latent representations*. Each of these representations (say,100d vector) are composed of many factors, we call it as 'Latent factors'(ref the above fig).If the representation has learnt the underlying factors from the data, then one or more latent factors are mapped/related to generative factors. In that case, the latent factors representing independent generative factors should remain disentangled with other generative factors.\n",
    "    For eg: this time we generate another image a \"big red apple\" (*generative factors*: size: big, color: red, fruit: apple) and feed into a DL to learn a representation. Now, the latent factor(s) sensitive to the generative factor(size) only should change and the other latent factors related to other generative factors (color, fruit) should not change as the Color and fruit still remains the same (still its a red apple, only size has changed)\n",
    "    Achieving this type of disentanglement in latent space is the key to achieve human like intelligence.\n",
    "![](my_icons/image11.png)\n",
    "\n",
    "+ **Interpretability**\n",
    "Though representations in low dimensional latent space are helpful to solve problems, interpreting them is often very hard. Disentangling the latent factors is one way to achieve interpretability. \n",
    "\n",
    "- For eg: Take two images (small red apple & big red apple) and feed into DL model to learn representation of both. Assuming the model has produced disentangled representation, we can find which units of latent vector Z are sensitive to changes in SIZE (small to red) by observing the difference between both. only the units that are sensitive to SIZE would be different in values(i.e have high variance) rest all units have minor or no changes.\n",
    "        \n",
    "- In the same way, each set of latent factors that are sensitive to each generative factors can be found.\n",
    "        \n",
    "- This interpretation offers us 2 benefits\n",
    "    - Solution simplification : Assume we need to find the red colored objects from images.If we know ehich hidden units are sensitive to color changes, the task can be solved with simple linear classifier\n",
    "            \n",
    "    - Targeted generation/modification : In the same way ,if we need to change the color of an object, we can just change the value of the hidden unit(sensitive to color) and then use the representation(z vector) to generate image\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the benefits of learning good representations?\n",
    "\n",
    "+ Transfer learning\n",
    "\n",
    "+ Multitask learning\n",
    "\n",
    "+ Simple Robust models\n",
    "\n",
    "+ Domain adaption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good representation helps to achieve generalization beyond the particular task. Hence it can used for"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
