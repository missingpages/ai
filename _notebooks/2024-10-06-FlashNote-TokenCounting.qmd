---
title: '"FlashPost'
jupyter: python3
---

    - To count message tokens to and from openAI LLM"
> "This post tells you different ways to count the tokens, both the input tokens sent to LLM and the tokens in output response"


#### 1. Set env key for openai

```{python}
from langchain_openai import ChatOpenAI
```

```{python}
import getpass
import os

if not os.environ.get("OPENAI_API_KEY"):
    os.environ["OPENAI_API_KEY"] = getpass.getpass("Enter your OpenAI API key: ")
```

#### 2. Use langchain
Lets use the langchain library to chat with LLM

```{python}
llm = ChatOpenAI(model= "gpt-4o-mini", temperature=0)
```

```{python}
#| echo: true
aimessage = llm.invoke("how are you?")
aimessage
```

```{python}
messages = [{"role":"user","content":"how are you?"}]
```

The above response message says **'prompt_tokens': 11** and **output tokens as 28** 

 lets verify it

#### 3. Verify with tiktoken library

```{python}
import tiktoken
```

```{python}
encoding = tiktoken.encoding_for_model("gpt-4o-mini")
```

```{python}
encoding.encode("how are you?")
```

Lets decode and verify the text

```{python}
encoding.decode([8923, 553, 481, 30])
```

we can also see how the tokens are split interactively by acccessing https://platform.openai.com/tokenizer

![](my_icons/fp1-1.png)

![](my_icons/fp1-2.png)

As seen above, the result above matches with the result from tiktoken library, however the count doesnot match with response AIMessage **why?**

As openAI expects the input request be sent with "role" and "content" as dictionary, langchain adds it internally even if we specify the message as plain string. we could check the details by turning on the debug mode  

![](my_icons/fp1-3.png)

```{python}
import langchain
langchain.debug=True
```

```{python}
llm.invoke("how are you?")
```

Now lets check what is the token count after putting it in proper format

```{python}
encoding.encode('{role:user,content:how are you?}')
```

And what is the content token length? It matches!

```{python}
len(encoding.encode(aimessage.content))
```


